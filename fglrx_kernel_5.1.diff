--- unpatched/common/lib/modules/fglrx/build_mod/kcl_wait.c	2017-06-04 13:38:45.112461362 -0600
+++ patched/common/lib/modules/fglrx/build_mod/kcl_wait.c	2017-10-14 17:03:55.203097495 -0600
@@ -43,6 +43,10 @@
 #include "kcl_config.h"
 #include "kcl_wait.h"
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+typedef wait_queue_entry_t wait_queue_t;
+#endif
+
 /** \brief Create wait object, init it and add to the kernel queue
  ** \param object_handle [in] Object handle
  ** \return Kernel wait handle on success, 0 otherwise
--- unpatched/common/lib/modules/fglrx/build_mod/drmP.h	2017-06-04 13:38:42.219487678 -0600
+++ patched/common/lib/modules/fglrx/build_mod/drmP.h	2021-05-02 14:53:16.704224208 -0600
@@ -218,12 +218,10 @@
 #define DRM_PROC_LIMIT (PAGE_SIZE-80)
 
 #define DRM_PROC_PRINT(fmt, arg...)					\
-   len += sprintf(&buf[len], fmt , ##arg);				\
-   if (len > DRM_PROC_LIMIT) { *eof = 1; return len - offset; }
+   if ((len += sprintf(&buf[len], fmt , ##arg)) > DRM_PROC_LIMIT) { *eof = 1; return len - offset; }
 
 #define DRM_PROC_PRINT_RET(ret, fmt, arg...)				\
-   len += sprintf(&buf[len], fmt , ##arg);				\
-   if (len > DRM_PROC_LIMIT) { ret; *eof = 1; return len - offset; }
+   if ((len += sprintf(&buf[len], fmt , ##arg)) > DRM_PROC_LIMIT) { ret; *eof = 1; return len - offset; }
 
 /*@}*/
 
diff -Naur unpatched/common/lib/modules/fglrx/build_mod/2.6.x/Makefile patched/common/lib/modules/fglrx/build_mod/2.6.x/Makefile
--- unpatched/common/lib/modules/fglrx/build_mod/2.6.x/Makefile	2019-01-22 17:25:01.973982320 -0700
+++ patched/common/lib/modules/fglrx/build_mod/2.6.x/Makefile	2021-05-02 14:53:16.703224219 -0600
@@ -27,7 +27,6 @@
 LIBIP_PREFIX	?= ..
 
 obj-m           += fglrx.o
-fglrx-libs      += libfglrx_ip.a
 
 fglrx-c-objs    += firegl_public.o      \
                    kcl_acpi.o           \
@@ -41,7 +40,7 @@
                    kcl.o                \
                    kcl_wait.o
 
-fglrx-objs      += $(fglrx-c-objs) $(fglrx-libs)
+fglrx-objs      += $(fglrx-c-objs)
 
 fglrx-hdrs      += firegl_public.h      \
                    fglrxko_pci_ids.h    \
@@ -69,6 +68,8 @@
                 -DFGL_LINUX253P1_VMA_API \
                 -DPAGE_ATTR_FIX=$(PAGE_ATTR_FIX) \
 
+EXTRA_LDFLAGS      := /usr/lib/fglrx/libfglrx_ip.a_shipped
+
 ifeq ($(KERNELRELEASE),)
 # on first call from remote location we get into this path
 # whilst on second call all is managed by the embedding kernel makefile
@@ -85,7 +86,7 @@
 # default:: kmod_build
 
 kmod_build:: $(fglrx-libs) $(fglrx-cfiles) $(fglrx-hdrs) $(drm-hdrs)
-	$(MAKE) -C $(KDIR) SUBDIRS=$(PWD) modules
+	$(MAKE) -C $(KDIR) M=$(PWD) modules
 
 %.c:
 	@ln -s ../$@
--- unpatched/common/lib/modules/fglrx/build_mod/2.6.x/Makefile	2019-01-22 17:25:01.973982320 -0700
+++ patched/common/lib/modules/fglrx/build_mod/2.6.x/Makefile	2021-05-02 14:53:16.703224219 -0600
@@ -27,7 +27,6 @@
 LIBIP_PREFIX	?= ..
 
 obj-m           += fglrx.o
-fglrx-libs      += libfglrx_ip.a
 
 fglrx-c-objs    += firegl_public.o      \
                    kcl_acpi.o           \
@@ -41,7 +40,7 @@
                    kcl.o                \
                    kcl_wait.o
 
-fglrx-objs      += $(fglrx-c-objs) $(fglrx-libs)
+fglrx-objs      += $(fglrx-c-objs)
 
 fglrx-hdrs      += firegl_public.h      \
                    fglrxko_pci_ids.h    \
@@ -69,6 +68,8 @@
                 -DFGL_LINUX253P1_VMA_API \
                 -DPAGE_ATTR_FIX=$(PAGE_ATTR_FIX) \
 
+EXTRA_LDFLAGS      := /usr/lib/fglrx/libfglrx_ip.a_shipped
+
 ifeq ($(KERNELRELEASE),)
 # on first call from remote location we get into this path
 # whilst on second call all is managed by the embedding kernel makefile
@@ -85,7 +86,7 @@
 # default:: kmod_build
 
 kmod_build:: $(fglrx-libs) $(fglrx-cfiles) $(fglrx-hdrs) $(drm-hdrs)
-	$(MAKE) -C $(KDIR) SUBDIRS=$(PWD) modules
+	$(MAKE) -C $(KDIR) M=$(PWD) modules
 
 %.c:
 	@ln -s ../$@
--- unpatched/common/lib/modules/fglrx/build_mod/kcl_pci.c	2017-06-04 13:38:45.112461362 -0600
+++ patched/common/lib/modules/fglrx/build_mod/kcl_pci.c	2018-07-14 14:03:29.575806619 -0600
@@ -59,7 +59,9 @@
 {
     struct pci_dev* pci_dev;
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,17,0)
+	pci_dev = pci_get_domain_bus_and_slot(0, busnum, PCI_DEVFN(devnum, funcnum));
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
     pci_dev = pci_get_bus_and_slot(busnum, PCI_DEVFN(devnum, funcnum));
 #else
     pci_dev = pci_find_slot(busnum, PCI_DEVFN(devnum, funcnum));
@@ -96,7 +98,9 @@
 KCL_PCI_DevHandle ATI_API_CALL KCL_PCI_GetDevHandle(
     KCL_TYPE_U32 bus, KCL_TYPE_U32 slot)
 {
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,17,0)
+    return (KCL_PCI_DevHandle)pci_get_domain_bus_and_slot(0, bus, slot);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
     return (KCL_PCI_DevHandle)pci_get_bus_and_slot(bus, slot);
 #else
     return (KCL_PCI_DevHandle)pci_find_slot(bus, slot);
--- unpatched/common/lib/modules/fglrx/build_mod/firegl_public.c	2017-06-04 13:38:43.621474925 -0600
+++ patched/common/lib/modules/fglrx/build_mod/firegl_public.c	2021-05-02 14:53:22.152170439 -0600
@@ -203,6 +203,18 @@
 #include <asm/fpu/internal.h>
 #endif
 #endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,11,0)
+#include <linux/mm.h>
+#include <linux/sched/signal.h>
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+#include <asm/set_memory.h>
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5,1,0)
+#include <uapi/linux/mman.h>// MAP_SHARED
+#endif
 
 #include "firegl_public.h"
 #include "kcl_osconfig.h"
@@ -285,7 +297,7 @@
 #endif
 
 #ifdef MODULE_LICENSE
-MODULE_LICENSE("Proprietary. (C) 2002 - ATI Technologies, Starnberg, GERMANY");
+MODULE_LICENSE("GPL");
 #endif
 #ifdef MODULE_DEVICE_TABLE
 MODULE_DEVICE_TABLE(pci, fglrx_pci_table);
@@ -631,8 +643,13 @@
 
     len = snprintf(buf, request, "%d\n", major);
 #else
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,3,0)
+    seq_printf(m, "%d\n", major);
+    len = 0;
+#else
     len = seq_printf(m, "%d\n", major);
 #endif
+#endif
 
     KCL_DEBUG1(FN_FIREGL_PROC, "return len=%i\n",len);
 
@@ -2728,12 +2745,12 @@
 
 int ATI_API_CALL KCL_MEM_VerifyReadAccess(void* addr, kcl_size_t size)
 {
-    return access_ok(VERIFY_READ, addr, size) ? 0 : -EFAULT;
+    return access_ok(addr, size) ? 0 : -EFAULT;
 }
 
 int ATI_API_CALL KCL_MEM_VerifyWriteAccess(void* addr, kcl_size_t size)
 {
-    return access_ok(VERIFY_WRITE, addr, size) ? 0 : -EFAULT;
+    return access_ok(addr, size) ? 0 : -EFAULT;
 }
 
 /** \brief Get Init kernel PTE by address. Couldn't be used for kernel >= 2.6.25.
@@ -2743,6 +2760,9 @@
 unsigned long ATI_API_CALL KCL_GetInitKerPte(unsigned long address)
 {
     pgd_t *pgd_p;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    p4d_t *p4d_p;
+#endif
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
     pud_t *pud_p;
 #endif
@@ -2757,7 +2777,13 @@
 #endif
     PGD_PRESENT(pgd_p);
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    P4D_OFFSET(p4d_p, pgd_p, address);
+    P4D_PRESENT(p4d_p);
+    PUD_OFFSET(pud_p, p4d_p, address);
+#else
     PUD_OFFSET(pud_p, pgd_p, address);
+#endif
     PUD_PRESENT(pud_p);
     PMD_OFFSET(pmd_p, pud_p, address);
 #else
@@ -2814,6 +2840,9 @@
         unsigned long * page_addr)
 {
     pgd_t* pgd_p;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    p4d_t *p4d_p;
+#endif
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
     pud_t* pud_p;
 #endif
@@ -2826,7 +2855,13 @@
     KCL_DEBUG2(FN_FIREGL_KCL,"pgd_p=0x%08lx\n", (unsigned long)pgd_p);
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    P4D_OFFSET(p4d_p, pgd_p, virtual_addr);
+    P4D_PRESENT(p4d_p);
+    PUD_OFFSET(pud_p, p4d_p, virtual_addr);
+#else
     PUD_OFFSET(pud_p, pgd_p, virtual_addr);
+#endif
     PUD_PRESENT(pud_p);
     KCL_DEBUG2(FN_FIREGL_KCL,"pud_p=0x%08lx\n", (unsigned long)pud_p);
     PMD_OFFSET(pmd_p, pud_p, virtual_addr);
@@ -2883,6 +2918,9 @@
         unsigned int  * page_size)
 {
     pgd_t* pgd_p;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    p4d_t *p4d_p;
+#endif
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
     pud_t* pud_p;
 #endif
@@ -2895,7 +2933,13 @@
     KCL_DEBUG2(FN_FIREGL_KCL,"pgd_p=0x%08lx\n", (unsigned long)pgd_p);
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    P4D_OFFSET(p4d_p, pgd_p, virtual_addr);
+    P4D_PRESENT(p4d_p);
+    PUD_OFFSET(pud_p, p4d_p, virtual_addr);
+#else
     PUD_OFFSET(pud_p, pgd_p, virtual_addr);
+#endif
     PUD_PRESENT(pud_p);
     KCL_DEBUG2(FN_FIREGL_KCL,"pud_p=0x%08lx\n", (unsigned long)pud_p);
     PMD_OFFSET(pmd_p, pud_p, virtual_addr);
@@ -2949,7 +2993,11 @@
 static void kcl_flush_tlb_one(void *va)
 {
     unsigned long *addr = (unsigned long *)va;
+#   if (LINUX_VERSION_CODE < KERNEL_VERSION(4,14,21))
     __flush_tlb_one(*addr);
+#   else
+    __flush_tlb_one_kernel(*addr);
+#   endif
 }
 
 /** /brief Flush one page on all cpus
@@ -3074,6 +3122,9 @@
 {
     int ret = -1; // init with page not present
     pgd_t* pgd_p;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    p4d_t *p4d_p;
+#endif
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
     pud_t* pud_p;
 #endif
@@ -3126,7 +3177,16 @@
          KCL_DEBUG1(FN_FIREGL_KCL,"pgd_p=0x%08lx\n", (unsigned long)pgd_p);
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
-         PUD_OFFSET(pud_p, pgd_p, page_addr);
+        #if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+        P4D_OFFSET(p4d_p, pgd_p, page_addr);
+        if (!p4d_present(*p4d_p)) {
+            KCL_DEBUG1(FN_FIREGL_KCL,"ERROR: !p4d_present\n");
+            continue;
+        }
+        PUD_OFFSET(pud_p, p4d_p, page_addr);
+        #else
+        PUD_OFFSET(pud_p, pgd_p, page_addr);
+        #endif
          if (!pud_present(*pud_p))
          {
              KCL_DEBUG1(FN_FIREGL_KCL,"ERROR: !pud_present\n");
@@ -3220,7 +3280,15 @@
     int ret;
 
     down_read(&current->mm->mmap_sem);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 1, (struct page **)page_list, NULL, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,9,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 1, (struct page **)page_list, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,6,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 1, 0, (struct page **)page_list, NULL);
+#else
     ret = get_user_pages(current, current->mm, vaddr, page_cnt, 1, 0, (struct page **)page_list, NULL);
+#endif
     up_read(&current->mm->mmap_sem);
 
     return ret;
@@ -3238,7 +3306,15 @@
     int ret;
 
     down_read(&current->mm->mmap_sem);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 0, (struct page **)page_list, NULL, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,9,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 0, (struct page **)page_list, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,6,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 0, 0, (struct page **)page_list, NULL);
+#else
     ret = get_user_pages(current, current->mm, vaddr, page_cnt, 0, 0, (struct page **)page_list, NULL);
+#endif
     up_read(&current->mm->mmap_sem);
 
     return ret;
@@ -3249,7 +3325,11 @@
     unsigned int i;
     for (i=0; i<page_cnt; i++)
     {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,6,0)
+        put_page((struct page*)page_list[i]);
+#else
         page_cache_release((struct page*)page_list[i]);
+#endif
     }
 }
 
@@ -3424,7 +3504,11 @@
 int ATI_API_CALL KCL_MEM_MTRR_AddRegionWc(unsigned long base, unsigned long size)
 {
 #ifdef CONFIG_MTRR
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,3,0)
+    return arch_phys_wc_add(base, size);
+#else
     return mtrr_add(base, size, MTRR_TYPE_WRCOMB, 1);
+#endif
 #else /* !CONFIG_MTRR */
     return -EPERM;
 #endif /* !CONFIG_MTRR */
@@ -3433,7 +3517,12 @@
 int ATI_API_CALL KCL_MEM_MTRR_DeleteRegion(int reg, unsigned long base, unsigned long size)
 {
 #ifdef CONFIG_MTRR
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,3,0)
+    arch_phys_wc_del(reg);
+    return reg;
+#else
     return mtrr_del(reg, base, size);
+#endif
 #else /* !CONFIG_MTRR */
     return -EPERM;
 #endif /* !CONFIG_MTRR */
@@ -3596,7 +3685,9 @@
     unsigned long vma_offset;
     unsigned long pte_linear;
     mem_map_t* pMmPage;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
 
@@ -3671,7 +3762,9 @@
 {
     unsigned long kaddr;
     mem_map_t* pMmPage;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
 
@@ -3716,7 +3809,9 @@
 {
     unsigned long kaddr;
     mem_map_t* pMmPage;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
 
@@ -3779,7 +3874,9 @@
     mem_map_t* pMmPage;
     struct firegl_pcie_mem* pciemem;
     unsigned long* pagelist;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
     
@@ -3841,7 +3938,9 @@
 
     unsigned long offset;
     struct page *page;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
 
@@ -4029,6 +4128,9 @@
                             kcl_dma_addr_t* phys_address)
 {
     pgd_t* pgd_p;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    p4d_t *p4d_p;
+#endif
     pmd_t* pmd_p;
     pte_t  pte;
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
@@ -4042,7 +4144,17 @@
         return buf;
     }
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
+    #if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+    p4d_p = p4d_offset(pgd_p, virtual_addr);
+    if (!p4d_present(*p4d_p))
+    {
+        *buf = 0;
+        return buf;
+    }
+    pud_p = pud_offset(p4d_p, virtual_addr);
+    #else
     pud_p = pud_offset(pgd_p, virtual_addr);
+    #endif
     if (!pud_present(*pud_p))
     {
         *buf = 0;
@@ -4136,12 +4248,50 @@
 
 #else
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+#define TRACE_FAULT(_f, _v,_a)                                          \
+   int  ret;                                                            \
+   KCL_DEBUG_TRACEIN(FN_DRM_NOPAGE, (unsigned long)_a->address, NULL); \
+   ret = _f(_v,_a);                                                     \
+   KCL_DEBUG_TRACEOUT(FN_DRM_NOPAGE, ret, NULL);                                \
+   return ret;
+#else
 #define TRACE_FAULT(_f, _v,_a)                                          \
    int  ret;                                                            \
    KCL_DEBUG_TRACEIN(FN_DRM_NOPAGE, (unsigned long)_a->virtual_address, NULL); \
    ret = _f(_v,_a);                                                     \
    KCL_DEBUG_TRACEOUT(FN_DRM_NOPAGE, ret, NULL);                                \
    return ret;
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,11,0)
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5,1,0)
+typedef unsigned int ip_vm_ret;
+#else
+typedef int ip_vm_ret;
+#endif
+
+static ip_vm_ret ip_vm_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_fault, vmf->vma, vmf);
+}
+static ip_vm_ret ip_vm_shm_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_shm_fault, vmf->vma, vmf);
+}
+static ip_vm_ret ip_vm_dma_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_dma_fault, vmf->vma, vmf);
+}
+static ip_vm_ret ip_vm_kmap_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_kmap_fault, vmf->vma, vmf);
+}
+static ip_vm_ret ip_vm_pcie_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_pcie_fault, vmf->vma, vmf);
+}
+static ip_vm_ret ip_vm_gart_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_gart_fault, vmf->vma, vmf);
+}
+
+#else /* LINUX_VERSION_CODE >= KERNEL_VERSION(4,11,0) */
 
 static int ip_vm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 {
@@ -4173,6 +4323,8 @@
     TRACE_FAULT(do_vm_gart_fault, vma, vmf);
 }
 
+#endif /* LINUX_VERSION_CODE >= KERNEL_VERSION(4,11,0) */
+
 #endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26) */
 
 static struct vm_operations_struct vm_ops =
@@ -4518,7 +4670,11 @@
     write_cr0(cr0);
     wbinvd();
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+    if (boot_cpu_has(X86_FEATURE_PGE))
+#else
     if (cpu_has_pge)
+#endif
     {
         cr4 = READ_CR4();
         WRITE_CR4(cr4 & ~X86_CR4_PGE);
@@ -4532,7 +4688,11 @@
     wbinvd();
     __flush_tlb();
     write_cr0(cr0 & 0xbfffffff);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+    if (boot_cpu_has(X86_FEATURE_PGE))
+#else
     if (cpu_has_pge)
+#endif
     {
         WRITE_CR4(cr4);
     }
@@ -4559,7 +4719,11 @@
     write_cr0(cr0);
     wbinvd();
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+    if (boot_cpu_has(X86_FEATURE_PGE))
+#else
     if (cpu_has_pge)
+#endif
     {
         cr4 = READ_CR4();
         WRITE_CR4(cr4 & ~X86_CR4_PGE);
@@ -4572,7 +4736,11 @@
     wbinvd();
     __flush_tlb();
     write_cr0(cr0 & 0xbfffffff);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+    if (boot_cpu_has(X86_FEATURE_PGE))
+#else
     if (cpu_has_pge)
+#endif
     {
         WRITE_CR4(cr4);
     }
@@ -6444,18 +6612,22 @@
     generate_random_uuid((char *)buf);
 }
 
+#ifndef CONFIG_X86_64
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0)
 static int KCL_fpu_save_init(struct task_struct *tsk)
 {
    struct fpu *fpu = &tsk->thread.fpu;
 
    if(static_cpu_has(X86_FEATURE_XSAVE)) {
-#if LINUX_VERSION_CODE < KERNEL_VERSION(4,2,0)
-      fpu_xsave(fpu);
-      if (!(fpu->state->xsave.xsave_hdr.xstate_bv & XSTATE_FP))
-#else
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	  copy_xregs_to_kernel(&fpu->state.xsave);
+      if (!(fpu->state.xsave.header.xfeatures & XFEATURE_MASK_FP))
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,2,0)
 	  copy_xregs_to_kernel(&fpu->state.xsave);
       if (!(fpu->state.xsave.header.xfeatures & XSTATE_FP))
+#else
+      fpu_xsave(fpu);
+      if (!(fpu->state->xsave.xsave_hdr.xstate_bv & XSTATE_FP))
 #endif
          return 1;
    } else if (static_cpu_has(X86_FEATURE_FXSR)) {
@@ -6483,6 +6655,8 @@
    return 1;
 }
 #endif
+#endif
+
 
 /** \brief Prepare for using FPU
  *  \param none
@@ -6491,13 +6665,8 @@
 void ATI_API_CALL KCL_fpu_begin(void)
 {
 #ifdef CONFIG_X86_64
-#if LINUX_VERSION_CODE < KERNEL_VERSION(4,2,0)
     kernel_fpu_begin();
 #else
-    preempt_disable();
-    __kernel_fpu_begin();
-#endif
-#else
 #ifdef TS_USEDFPU
     struct thread_info *cur_thread = current_thread_info();
     struct task_struct *cur_task = get_current();
@@ -6546,12 +6715,7 @@
  */
 void ATI_API_CALL KCL_fpu_end(void)
 {
-#if LINUX_VERSION_CODE < KERNEL_VERSION(4,2,0)
     kernel_fpu_end();
-#else
-    __kernel_fpu_end();
-    preempt_enable();
-#endif
 }
 
 /** Create new directory entry under "/proc/...."
--- unpatched/common/lib/modules/fglrx/build_mod/kcl_ioctl.c	2017-06-04 13:38:45.112461362 -0600
+++ patched/common/lib/modules/fglrx/build_mod/kcl_ioctl.c	2021-05-02 14:53:16.781223449 -0600
@@ -30,7 +30,10 @@
  *
  */
 
+#include <linux/cache.h>
+#include <linux/sched.h> // for task_struct in asm/current.h
 #include <linux/version.h>
+#include <asm/processor.h> // for mm_segment_t in asm/uaccess.h
 #include <asm/uaccess.h>
 
 #ifdef __x86_64__
@@ -225,7 +228,7 @@
     void __user *ret = COMPAT_ALLOC_USER_SPACE(size);
 
     /* prevent stack overflow */
-    if (!access_ok(VERIFY_WRITE, ret, size))
+    if (!access_ok(ret, size))
         return NULL;
 
     return (void *)ret;
--- unpatched/common/lib/modules/fglrx/build_mod/firegl_public.h	2017-06-04 13:38:44.410467748 -0600
+++ patched/common/lib/modules/fglrx/build_mod/firegl_public.h	2021-05-02 14:53:16.781223449 -0600
@@ -91,6 +91,23 @@
     } \
 } while(0)
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+#define P4D_OFFSET(p4d_p, pgd_p, pte_linear)  \
+do { \
+    p4d_p = p4d_offset(pgd_p, pte_linear); \
+} while(0)
+
+#define P4D_PRESENT(p4d_p) \
+do { \
+    if (!p4d_present(*(p4d_p))) \
+    { \
+        return PAGING_FAULT_SIGBUS_INT;   /* Something bad happened; generate SIGBUS */ \
+        /* alternatively we could generate a NOPAGE_OOM "out of memory" */ \
+    } \
+} while(0)
+
+#endif // LINUX_VERSION_CODE >= KERNEL_VERSION(4,12,0)
+
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
 #define PUD_PRESENT(pud_p) \
 do { \
@@ -650,9 +667,15 @@
 #define cpu_has_pat  test_bit(X86_FEATURE_PAT, (void *) &boot_cpu_data.x86_capability)
 #endif
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+#ifndef boot_cpu_has
+#define boot_cpu_has(X86_FEATURE_PGE) test_bit(X86_FEATURE_PGE, &boot_cpu_data.x86_capability)
+#endif
+#else
 #ifndef cpu_has_pge
 #define cpu_has_pge test_bit(X86_FEATURE_PGE, &boot_cpu_data.x86_capability)
 #endif
+#endif
 
 /* 2.6.29 defines pgprot_writecombine as a macro which resolves to a
  * GPL-only function with the same name. So we always use our own
--- unpatched/common/lib/modules/fglrx/build_mod/kcl_acpi.c	2017-06-04 13:38:45.077461680 -0600
+++ patched/common/lib/modules/fglrx/build_mod/kcl_acpi.c	2017-06-04 13:54:58.351993538 -0600
@@ -359,7 +359,10 @@
 {
     struct acpi_table_header *hdr;
     acpi_size tbl_size ;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,3)    
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    tbl_size = hdr->length;
+    if (!ACPI_SUCCESS(acpi_get_table("VFCT", 1, &hdr)))
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,3)    
     if (!ACPI_SUCCESS(acpi_get_table_with_size("VFCT", 1, &hdr, &tbl_size)))
 #else
     tbl_size = 0x7fffffff;
@@ -1029,7 +1032,10 @@
         return KCL_ACPI_ERROR; 
     }
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,3)    
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    tbl_size = hdr->length;
+    if (!ACPI_SUCCESS(acpi_get_table(id, 0, &hdr)))
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,3)
     if (!ACPI_SUCCESS(acpi_get_table_with_size(id, 0, &hdr, &tbl_size)))
 #else
     tbl_size = 0x7fffffff;
--- unpatched/common/lib/modules/fglrx/build_mod/kcl.c	2017-06-04 13:38:45.112461362 -0600
+++ patched/common/lib/modules/fglrx/build_mod/kcl.c	2017-06-04 13:56:43.386282643 -0600
@@ -30,6 +30,11 @@
 #include <linux/slab.h>
 #include <linux/pci.h>
 
+#include <linux/version.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,11,0)
+#include <linux/sched/signal.h>
+#endif
+
 #define SUSPEND_CONSOLE  (MAX_NR_CONSOLES-1)
 
 /** \brief Send signal to a specified pid
@@ -128,4 +133,4 @@
     pFirmware->fw = NULL;
     
     return 0;
-}
\ No newline at end of file
+}
